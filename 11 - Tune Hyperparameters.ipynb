{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 微調超參數\n",
        "\n",
        "有許多機器學習演算法需要「超參數」(可影響定型但無法從定型資料本身決定的參數值)。例如，定型羅吉迴歸模型時，您可以使用「正規化比率」超參數來對抗模型中的偏差；或者，定型卷積神經網路時，您可以使用「學習速率」和「批次大小」這類超參數來控制如何調整加權，以及在迷你批次期間分別處理多少資料項目。超參數值的選項可能會大幅影響已定型模型的效能，或用來對其進行定型所花費的時間；而且，您通常需要嘗試多個組合，才能找到最佳解決方案。\n",
        "\n",
        "在此情況下，您將會使用兩個超參數來定型分類模型，但準則會套用至您可使用 Azure Machine Learning 來定型的任何模型類型。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 連線至您的工作區\n",
        "\n",
        "若要開始進行，請連線至您的工作區。\n",
        "\n",
        "> **注意**：如果您尚未使用 Azure 訂用帳戶建立已驗證的工作階段，則系統會提示您按一下連結、輸入驗證碼並登入 Azure 來進行驗證。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1649367790637
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 準備資料\n",
        "\n",
        "在此實驗室中，您將使用包含糖尿病病患詳細資料的資料集。執行下方的儲存格來建立此資料集 (如果已經存在，則將會使用現有版本)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "if 'diabetes dataset' not in ws.datasets:\n",
        "    default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'], # Upload the diabetes csv files in /data\n",
        "                        target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
        "                        overwrite=True, # Replace existing files of the same name\n",
        "                        show_progress=True)\n",
        "\n",
        "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
        "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "    # Register the tabular dataset\n",
        "    try:\n",
        "        tab_data_set = tab_data_set.register(workspace=ws, \n",
        "                                name='diabetes dataset',\n",
        "                                description='diabetes data',\n",
        "                                tags = {'format':'CSV'},\n",
        "                                create_new_version=True)\n",
        "        print('Dataset registered.')\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "else:\n",
        "    print('Dataset already registered.')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 準備定型指令碼\n",
        "\n",
        "現在，請建立定型指令碼的資料夾，而您將使用此指令碼來定型模型。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "experiment_folder = 'diabetes_training-hyperdrive'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "\n",
        "print('Folder ready.')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "現在，請建立 Python 指令碼來定型模型。在此範例中，您將使用「梯度提升」演算法來定型分類模型。指令碼必須包括：\n",
        "\n",
        "- 每個您想要最佳化的超參數的引數 (在此情況下，是梯度提升演算法的學習速率和估算器數目)\n",
        "- 可記錄您想要最佳化效能計量的程式碼 (在此情況下，您將會記錄 AUC 和正確性，因此您可以選擇最佳化其中任一種的模型)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/diabetes_training.py\n",
        "# Import libraries\n",
        "import argparse, joblib, os\n",
        "from azureml.core import Run\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# Get script arguments\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "# Input dataset\n",
        "parser.add_argument(\"--input-data\", type=str, dest='input_data', help='training dataset')\n",
        "\n",
        "# Hyperparameters\n",
        "parser.add_argument('--learning_rate', type=float, dest='learning_rate', default=0.1, help='learning rate')\n",
        "parser.add_argument('--n_estimators', type=int, dest='n_estimators', default=100, help='number of estimators')\n",
        "\n",
        "# Add arguments to args collection\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Log Hyperparameter values\n",
        "run.log('learning_rate',  np.float(args.learning_rate))\n",
        "run.log('n_estimators',  np.int(args.n_estimators))\n",
        "\n",
        "# load the diabetes dataset\n",
        "print(\"Loading Data...\")\n",
        "diabetes = run.input_datasets['training_data'].to_pandas_dataframe() # Get the training data from the estimator input\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train a Gradient Boosting classification model with the specified hyperparameters\n",
        "print('Training a classification model')\n",
        "model = GradientBoostingClassifier(learning_rate=args.learning_rate,\n",
        "                                   n_estimators=args.n_estimators).fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "# Save the model in the run outputs\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
        "\n",
        "run.complete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 建立計算\n",
        "\n",
        "超參數微調包含執行多次具有不同超參數值的定型反覆運算，以及比較所產生模型的效能計量。為了有效率地執行這項作業，我們將利用隨選雲端計算，並建立叢集 - 這將允許同時執行多個定型反覆項目。\n",
        "\n",
        "使用下列程式碼，以指定 Azure Machine Learning 計算叢集 (如果尚未存在，則系統會加以建立)。\n",
        "\n",
        "> **重要**：在執行前，請先將 *your-compute-cluster* 的名稱，變更為程式碼中計算叢集的名稱！叢集名稱必須是全域唯一且長度介於 2 到 16 個字元的名稱。有效字元包括字母、數字及 - 字元。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"your-compute-cluster\"\n",
        "\n",
        "try:\n",
        "    # Check for existing compute target\n",
        "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # If it doesn't already exist, create it\n",
        "    try:\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
        "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "        training_cluster.wait_for_completion(show_output=True)\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "    "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **注意**：計算執行個體和叢集是以標準 Azure 虛擬機器映像為基礎。針對此練習，建議使用 *Standard_DS11_v2* 映像，以達到成本與效能的最佳平衡。如果您的訂用帳戶具有不包含此映像的配額，請選擇替代映像；但請記得，較大的映像可能會產生較高的成本，而較小的映像可能不足以完成工作。或者，請要求您的 Azure 系統管理員擴大您的配額。\n",
        "\n",
        "您將需要在計算上裝載 Python 環境，因此請將其定義為 Conda 設定檔。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/hyperdrive_env.yml\n",
        "name: batch_environment\n",
        "dependencies:\n",
        "- python=3.6.2\n",
        "- scikit-learn\n",
        "- pandas\n",
        "- numpy\n",
        "- pip\n",
        "- pip:\n",
        "  - azureml-defaults\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 執行超參數微調實驗\n",
        "\n",
        "Azure Machine Learning 包括透過 Hyperdrive 實驗來執行超參數微調功能。這些實驗會啟動多個子執行，而且各有不同的超參數組合。可以識別出產生最佳模型的執行 (由您想要最佳化的已記錄目標效能計量所決定)，並且已選取其已定型模型以進行註冊和部署。\n",
        "\n",
        "> **注意**：在此範例中，我們未指定提早停止原則。只有在定型指令碼執行多次定型反覆運算並記錄每次反覆運算的主要計量時，這類原則才相關。透過多個 Epoch 來定型深度神經網路模型時，一般會使用此方式。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
        "from azureml.train.hyperdrive import GridParameterSampling, HyperDriveConfig, PrimaryMetricGoal, choice\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Create a Python environment for the experiment\n",
        "hyper_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/hyperdrive_env.yml\")\n",
        "\n",
        "# Get the training dataset\n",
        "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
        "\n",
        "# Create a script config\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                                script='diabetes_training.py',\n",
        "                                # Add non-hyperparameter arguments -in this case, the training dataset\n",
        "                                arguments = ['--input-data', diabetes_ds.as_named_input('training_data')],\n",
        "                                environment=hyper_env,\n",
        "                                compute_target = training_cluster)\n",
        "\n",
        "# Sample a range of parameter values\n",
        "params = GridParameterSampling(\n",
        "    {\n",
        "        # Hyperdrive will try 6 combinations, adding these as script arguments\n",
        "        '--learning_rate': choice(0.01, 0.1, 1.0),\n",
        "        '--n_estimators' : choice(10, 100)\n",
        "    }\n",
        ")\n",
        "\n",
        "# Configure hyperdrive settings\n",
        "hyperdrive = HyperDriveConfig(run_config=script_config, \n",
        "                          hyperparameter_sampling=params, \n",
        "                          policy=None, # No early stopping policy\n",
        "                          primary_metric_name='AUC', # Find the highest AUC metric\n",
        "                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
        "                          max_total_runs=6, # Restict the experiment to 6 iterations\n",
        "                          max_concurrent_runs=2) # Run up to 2 iterations in parallel\n",
        "\n",
        "# Run the experiment\n",
        "experiment = Experiment(workspace=ws, name='mslearn-diabetes-hyperdrive')\n",
        "run = experiment.submit(config=hyperdrive)\n",
        "\n",
        "# Show the status in the notebook as the experiment runs\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "您可以在上方的小工具中檢視實驗執行狀態。您也可以在 [Azure Machine Learning 工作室](https://ml.azure.com) 中檢視主要 Hyperdrive 實驗執行和其子執行。\n",
        "\n",
        "> **注意**：如果顯示指出無法視覺化非數值的訊息，則您可以將其忽略。\n",
        "\n",
        "## 決定執行效能最佳的執行\n",
        "\n",
        "已完成所有執行時，您可以根據所指定的效能計量來找到最佳執行 (在此情況下，是具有最佳 AUC 的執行)。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all child runs, sorted by the primary metric\n",
        "for child_run in run.get_children_sorted_by_primary_metric():\n",
        "    print(child_run)\n",
        "\n",
        "# Get the best run, and its metrics and arguments\n",
        "best_run = run.get_best_run_by_primary_metric()\n",
        "best_run_metrics = best_run.get_metrics()\n",
        "script_arguments = best_run.get_details() ['runDefinition']['arguments']\n",
        "print('Best Run Id: ', best_run.id)\n",
        "print(' -AUC:', best_run_metrics['AUC'])\n",
        "print(' -Accuracy:', best_run_metrics['Accuracy'])\n",
        "print(' -Arguments:',script_arguments)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "既然，您已找到最佳執行，就可以註冊其所定型的模型。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "# Register model\n",
        "best_run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
        "                        tags={'Training context':'Hyperdrive'},\n",
        "                        properties={'AUC': best_run_metrics['AUC'], 'Accuracy': best_run_metrics['Accuracy']})\n",
        "\n",
        "# List registered models\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **詳細資訊**：如需 Hyperdrive 的詳細資訊，請參閱 [Azure ML 文件](https://docs.microsoft.com/azure/machine-learning/how-to-tune-hyperparameters)。"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}