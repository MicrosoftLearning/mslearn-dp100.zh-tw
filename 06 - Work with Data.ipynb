{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 使用資料\n",
        "\n",
        "資料是建立機器學習模型的基礎。在雲端集中管理資料，並讓在多個工作站和計算目標上執行實驗和訓練模型的資料科學家小組可以存取資料，是任何專業資料科學解決方案中非常重要的一環。\n",
        "\n",
        "在此筆記本中，您將探索兩個用於處理資料的 Azure Machine Learning 物件：*資料存放區* 和 *資料集*。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 連線到您的工作區\n",
        "\n",
        "若要開始進行，請連線到您的工作區。\n",
        "\n",
        "> **注意**：如果您尚未使用 Azure 訂閱建立已驗證的工作階段，系統會提示您透過按一下連結、輸入驗證碼並登入 Azure 來進行驗證。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366182180
        }
      },
      "outputs": [],
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 使用資料存放區\n",
        "\n",
        "在 Azure ML 中，*資料存放區* 意指儲存位置，如 Azure 儲存體 Blob 容器。每個工作區都有一個預設資料存放區；這通常是使用工作區建立的 Azure 儲存體 Blob 容器。若您需要使用儲存在不同位置的資料，您可以將自訂資料存放區新增至工作區，並將其中任何一個資料存放區設為預設。\n",
        "\n",
        "### 檢視資料存放區\n",
        "\n",
        "執行下列程式碼以判斷工作區中的資料存放區："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366185140
        }
      },
      "outputs": [],
      "source": [
        "# Get the default datastore\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "# Enumerate all datastores, indicating which is the default\n",
        "for ds_name in ws.datastores:\n",
        "    print(ds_name, \"- Default =\", ds_name == default_ds.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "您也可以在 [Azure Machine Learning 工作室](https://ml.azure.com)，於工作區的 **資料存放區** 頁面上，查看及管理工作區中的資料存放區。\n",
        "\n",
        "### 將資料上傳至資料存放區\n",
        "\n",
        "現在您已確定可用的資料存放區，您就可以從本機檔案系統將檔案上傳至資料存放區，讓其可供工作區中正在執行的實驗存取，無論實驗指令碼是否正在實際執行。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366190608
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Dataset\n",
        "from azureml.data.datapath import DataPath\n",
        "\n",
        "Dataset.File.upload_directory(src_dir='data',\n",
        "                              target=DataPath(default_ds, 'diabetes-data/')\n",
        "                              )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 使用資料集\n",
        "\n",
        "Azure Machine Learning 會以 *資料集* 的形式提供資料的抽象概要。資料集是一種特定資料集的版本化參考，建議將其用於實驗中。資料集可以是基於 *表格* 或 *檔案*。\n",
        "\n",
        "### 建立表格式資料集\n",
        "\n",
        "讓我們使用您上傳至資料存放區的糖尿病資料建立資料集，並檢視前 20 筆記錄。在此情況下，CSV 檔案中的資料會採用結構化格式，因此我們將使用 *表格式* 資料集。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366193530
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "# Get the default datastore\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "#Create a tabular dataset from the path on the datastore (this may take a short while)\n",
        "tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "# Display the first 20 rows as a Pandas dataframe\n",
        "tab_data_set.take(20).to_pandas_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "就如您在上方程式碼所見，將表格式資料集轉換為 Pandas 資料框架十分容易，可讓您運用一般 Python 技術使用資料。\n",
        "\n",
        "### 建立檔案資料集\n",
        "\n",
        "您所建立的資料集為 *表格式* 資料集，其可在位於資料集定義內且包含所有資料的結構化檔案中讀取為資料框架。這適用於表格式資料，但在部分機器學習案例中，您可能需要使用非結構化的資料；或者，建議您直接在自己的程式碼中，從檔案內處理資料讀取。若要完成這項操作，您可以使用 *檔案* 資料集來在虛擬掛接點中建立檔案路徑清單，您可以用它來讀取檔案中的資料。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366196795
        }
      },
      "outputs": [],
      "source": [
        "#Create a file dataset from the path on the datastore (this may take a short while)\n",
        "file_data_set = Dataset.File.from_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "# Get the files in the dataset\n",
        "for file_path in file_data_set.to_path():\n",
        "    print(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 註冊資料集\n",
        "\n",
        "現在您已建立參考糖尿病資料的資料集，您可以加以註冊，使工作區中執行的任何實驗輕鬆存取資料集。\n",
        "\n",
        "我們會將表格式資料集註冊為 **糖尿病資料集**，並將檔案資料集註冊為 **糖尿病資料*。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366200005
        }
      },
      "outputs": [],
      "source": [
        "# Register the tabular dataset\n",
        "try:\n",
        "    tab_data_set = tab_data_set.register(workspace=ws, \n",
        "                                        name='diabetes dataset',\n",
        "                                        description='diabetes data',\n",
        "                                        tags = {'format':'CSV'},\n",
        "                                        create_new_version=True)\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "\n",
        "# Register the file dataset\n",
        "try:\n",
        "    file_data_set = file_data_set.register(workspace=ws,\n",
        "                                            name='diabetes file dataset',\n",
        "                                            description='diabetes files',\n",
        "                                            tags = {'format':'CSV'},\n",
        "                                            create_new_version=True)\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "\n",
        "print('Datasets registered')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "您可以在 [Azure Machine Learning 工作室](https://ml.azure.com) 中工作區的 **資料集** 頁面上，查看及管理資料集。您可以從工作區物件取得資料集的清單："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366204696
        }
      },
      "outputs": [],
      "source": [
        "print(\"Datasets:\")\n",
        "for dataset_name in list(ws.datasets.keys()):\n",
        "    dataset = Dataset.get_by_name(ws, dataset_name)\n",
        "    print(\"\\t\", dataset.name, 'version', dataset.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "版本資料集的功能可讓您重新定義資料集，而不會中斷依賴於先前定義的現有實驗或管線。預設會傳回最新版本的具名資料集，但您可以藉由指定版本號碼來擷取資料集的特定版本，如下列所示：\n",
        "\n",
        "```python\n",
        "dataset_v1 = Dataset.get_by_name(ws, 'diabetes dataset', version = 1)\n",
        "```\n",
        "\n",
        "\n",
        "### 在表格式資料集中訓練模型\n",
        "\n",
        "現在您已擁有資料集，您已經可以開始使用資料集來訓練模型。您可以在用來執行指令碼的估算器中，將資料集以 *輸入* 的形式傳遞給指令碼。\n",
        "\n",
        "執行下列兩個程式碼儲存格來建立：\n",
        "\n",
        "1.名為 **diabetes_training_from_tab_dataset** 的資料夾\n",
        "2.訓練分類模型的指令碼，其訓練方法為使用作為引數傳遞給分類模型的表格式資料集。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366207914
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create a folder for the experiment files\n",
        "experiment_folder = 'diabetes_training_from_tab_dataset'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "print(experiment_folder, 'folder created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $experiment_folder/diabetes_training.py\n",
        "# Import libraries\n",
        "import os\n",
        "import argparse\n",
        "from azureml.core import Run, Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# Get the script arguments (regularization rate and training dataset ID)\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
        "parser.add_argument(\"--input-data\", type=str, dest='training_dataset_id', help='training dataset')\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Set regularization hyperparameter (passed as an argument to the script)\n",
        "reg = args.reg_rate\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# Get the training dataset\n",
        "print(\"Loading Data...\")\n",
        "diabetes = run.input_datasets['training_data'].to_pandas_dataframe()\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train a logistic regression model\n",
        "print('Training a logistic regression model with regularization rate of', reg)\n",
        "run.log('Regularization Rate',  np.float(reg))\n",
        "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
        "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
        "\n",
        "run.complete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **注意**：在指令碼中，會將資料集作為參數 (或引數) 傳遞。在表格式資料集的案例中，此引數會包含已註冊資料集的識別碼。因此，您可以在指令碼中撰寫程式碼，從執行內容取得實驗的工作區，然後使用其識別碼取得資料集。如同下列範例：\n",
        ">\n",
        "> ```\n",
        "> run = Run.get_context()\n",
        "> ws = run.experiment.workspace\n",
        "> dataset = Dataset.get_by_id(ws, id=args.training_dataset_id)\n",
        "> diabetes = dataset.to_pandas_dataframe()\n",
        "> ```\n",
        ">\n",
        "> 不過，Azure Machine Learning 會自動執行參考具名資料集的身分識別引數，並將其新增至執行的 **input_datasets** 集合，因此您也可以透過指定集合的「自訂名稱」，以擷取集合的資料集 (您會在稍後見到「自訂名稱」，該名稱指定於指令碼的引數定義中，且該指令碼會為實驗執行設定)。這就是以上指令碼所採取的方法。\n",
        "\n",
        "現在您可以將指令碼作為實驗執行，為訓練資料集定義引數，而資料集會由指令碼準備就緒。\n",
        "\n",
        "> **注意**：**資料集** 類別取決於 **azureml-dataprep** 套件中的部分元件，所以您需要在執行訓練實驗的環境內包含此套件。**azureml-dataprep** 套件包含在 **azure-defaults** 套件中。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366222016
        },
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
        "from azureml.core.runconfig import DockerConfiguration\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "\n",
        "# Create a Python environment for the experiment (from a .yml file)\n",
        "env = Environment.from_conda_specification(\"experiment_env\", \"environment.yml\")\n",
        "\n",
        "# Get the training dataset\n",
        "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
        "\n",
        "# Create a script config\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                              script='diabetes_training.py',\n",
        "                              arguments = ['--regularization', 0.1, # Regularizaton rate parameter\n",
        "                                           '--input-data', diabetes_ds.as_named_input('training_data')], # Reference to dataset\n",
        "                              environment=env,\n",
        "                              docker_runtime_config=DockerConfiguration(use_docker=True)) \n",
        "\n",
        "# submit the experiment\n",
        "experiment_name = 'mslearn-train-diabetes'\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "run = experiment.submit(config=script_config)\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **注意**：**--input-data** 引數可將資料集作為 *具名輸入* 傳遞，該輸入包含一項資料集的 *自訂名稱*，且資料集被指令碼用於在實驗執行中的 **input_datasets** 集合內讀取。**--input-data** 引數內的字串值，實際為已註冊資料集的識別碼。 作為替代方法，您可以直接傳遞 `diabetes_ds.id`。在此情況下，指令碼可以存取指令碼引數的資料集識別碼，並用其取得工作區的資料集，但無法取得 **input_datasets** 集合內的資料集。\n",
        "\n",
        "在實驗首次執行時，可能會需要一點時間來設定 Python 環境；之後執行實驗時，所需時間會較少。\n",
        "\n",
        "當實驗完成時，請在 widget 中檢視執行所產生的 **azureml-logs/70_driver_log.txt** 輸出記錄和計量。\n",
        "\n",
        "### 註冊已訓練的模型\n",
        "\n",
        "如同任何訓練實驗一樣，您可以擷取已訓練的模型，並在 Azure Machine Learning 工作區中加以註冊。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366229781
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
        "                   tags={'Training context':'Tabular dataset'}, properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
        "\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 在檔案資料集訓練模型\n",
        "\n",
        "您已了解如何使用 *表格式* 資料集中的訓練資料來訓練模型；但是您了解如何使用 *檔案* 資料集嗎？\n",
        "\n",
        "當您使用檔案資料集時，資料集引數會傳遞至代表掛接點的指令碼，該掛接點包含檔案路徑。您從這些檔案讀取資料的方式，取決於檔案中的資料類型，以及您處理它的方式。在糖尿病 CSV 檔案的案例中，您可以使用 Python **glob** 模組來建立資料集所定義虛擬掛接點中的檔案清單，並將它們全部讀入 Pandas 資料框架中，並串連成單一資料框架。\n",
        "\n",
        "執行下列兩個程式碼儲存格來建立：\n",
        "\n",
        "1.名為 **diabetes_training_from_file_dataset** 的資料夾\n",
        "2.訓練分類模型的指令碼，其使用作為 *輸入* 傳遞給分類模型的檔案資料集。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366232676
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create a folder for the experiment files\n",
        "experiment_folder = 'diabetes_training_from_file_dataset'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "print(experiment_folder, 'folder created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $experiment_folder/diabetes_training.py\n",
        "# Import libraries\n",
        "import os\n",
        "import argparse\n",
        "from azureml.core import Dataset, Run\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import glob\n",
        "\n",
        "# Get script arguments (rgularization rate and file dataset mount point)\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
        "parser.add_argument('--input-data', type=str, dest='dataset_folder', help='data mount point')\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Set regularization hyperparameter (passed as an argument to the script)\n",
        "reg = args.reg_rate\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the diabetes dataset\n",
        "print(\"Loading Data...\")\n",
        "data_path = run.input_datasets['training_files'] # Get the training data path from the input\n",
        "# (You could also just use args.dataset_folder if you don't want to rely on a hard-coded friendly name)\n",
        "\n",
        "# Read the files\n",
        "all_files = glob.glob(data_path + \"/*.csv\")\n",
        "diabetes = pd.concat((pd.read_csv(f) for f in all_files), sort=False)\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train a logistic regression model\n",
        "print('Training a logistic regression model with regularization rate of', reg)\n",
        "run.log('Regularization Rate',  np.float(reg))\n",
        "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
        "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
        "\n",
        "run.complete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "如同表格式資料集，您可以使用檔案資料集的自訂名稱，從 **input_datasets** 集合中擷取檔案資料集。在檔案資料集包含檔案的掛接路徑 (而不是針對表格式資料集所傳遞的資料集識別碼) 的情況下，您也可以從指令碼引數中擷取檔案資料集。\n",
        "\n",
        "接下來，我們需要變更將資料集傳遞至指令碼的方式；它需要定義指令碼可從中讀取檔案的路徑。您可以使用 **as_download** 或 **as_mount** 方法來執行此操作。使用 **as_download** 會導致檔案資料集中的檔案被下載至正在執行指令碼之電腦的暫時位置，而 **as_mount** 則會建立掛接點，您可以在掛接點中直接從資料存放區串流檔案。\n",
        "\n",
        "你可以將存取方法與 **as_named_input** 方法合併運用，以在實驗執行中包含 **input_datasets** 集合內的資料集 (若您省略此操作，舉例來說，將引數設定為 `diabetes_ds.as_mount()`，則指令碼將能在指令碼引數中存取資料集掛接點，但不能在 **input_datasets** 集合中存取)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366252096
        },
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.core.runconfig import DockerConfiguration\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "\n",
        "# Get the training dataset\n",
        "diabetes_ds = ws.datasets.get(\"diabetes file dataset\")\n",
        "\n",
        "# Create a script config\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                                script='diabetes_training.py',\n",
        "                                arguments = ['--regularization', 0.1, # Regularizaton rate parameter\n",
        "                                             '--input-data', diabetes_ds.as_named_input('training_files').as_download()], # Reference to dataset location\n",
        "                                environment=env, # Use the environment created previously\n",
        "                                docker_runtime_config=DockerConfiguration(use_docker=True))\n",
        "\n",
        "# submit the experiment\n",
        "experiment_name = 'mslearn-train-diabetes'\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "run = experiment.submit(config=script_config)\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "當實驗完成時，請在 widget 中檢視 **azureml-logs/70_driver_log.txt** 輸出記錄，以驗證檔案資料集內的檔案已下載至暫時資料夾，使指令碼得以讀取檔案。\n",
        "\n",
        "### 註冊已訓練的模型\n",
        "\n",
        "同樣地，您可以註冊由實驗訓練的模型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366260993
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
        "                   tags={'Training context':'File dataset'}, properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
        "\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **詳細資訊**：如需使用資料集訓練的詳細資訊，請參閱 Azure ML 文件中的 [使用資料集進行訓練](https://docs.microsoft.com/azure/machine-learning/how-to-train-with-datasets) (機器翻譯)。"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
